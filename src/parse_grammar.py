#!/usr/bin/env python3

# When Bison is invoked with the -v flag, it generates a "parser.output" file describing each generated rule and state
# of the parser. Additionally, the --xml outputs this file encoded as XML. The purpose of this Python script is to parse
# this generated grammar XML file and extract any useful information that can be used to enhance the compiler's syntax
# error reporting. CMakeLists.txt has been configured to invoke this script every time Bison's generated files are
# updated, and the C++ header generated by this script is incorporated into the rest of the compiler.

import json
import sys
import typing
import xml.etree.ElementTree as ET


def escape(s: str) -> str:
    if s is None:
        return ""
    return json.dumps(s)


class Rule:
    def __init__(self, number: int, lhs: str, rhs: typing.List[str]):
        self.number = number
        self.lhs = escape(lhs)
        self.rhs = [escape(s) for s in rhs]

    def __str__(self):
        return f'Rule {self.number}: ({self.lhs} : {self.rhs})'

    def __repr__(self):
        return self.__str__()


class StateRule:
    def __init__(self, rule: int, transition: int, point: int, lookaheads: typing.List[str]):
        self.rule = rule
        self.transition = transition
        self.point = point
        self.lookaheads = [escape(s) for s in lookaheads]


class State:
    def __init__(self, number: int, rules: typing.List[StateRule]):
        self.number = number
        self.rules = rules


class Grammar:
    def __init__(self, rules: typing.List[Rule], states: typing.List[State]):
        self.rules = rules
        self.states = states


def parse_rule(rule: ET.Element) -> Rule:
    number = int(rule.attrib['number'])
    lhs = rule.find('./lhs')
    rhs = rule.find('./rhs')
    rhs_text = []
    for symbol in rhs:
        rhs_text.append(symbol.text)
    return Rule(number, lhs.text, rhs_text)


def parse_state(state: ET.Element, rules: typing.List[Rule]) -> State:
    number = int(state.attrib['number'])
    transitions = {}
    for action in state.find('./actions/transitions'):
        transitions[escape(action.attrib['symbol'])] = int(action.attrib['state'])
    state_rules = []
    for item in state.find('./itemset'):
        rule_id = int(item.attrib['rule-number'])
        if 'point' in item.attrib:
            point = int(item.attrib['point'])
        elif 'dot' in item.attrib:
            point = int(item.attrib['dot'])
        else:
            sys.exit(f"unrecognized attrib schema: {item.attrib.keys()}")
        lookaheads = []
        la = item.find('./lookaheads')
        if la:
            for symbol in la.findall('./symbol'):
                lookaheads.append(symbol.text)
        rule = rules[rule_id]
        if point < len(rule.rhs):
            symbol = rule.rhs[point]
            transition = transitions[symbol] if symbol else -1
        else:
            transition = -1
        state_rules.append(StateRule(rule_id, transition, point, lookaheads))
    return State(number, state_rules)


def process_grammar(file: typing.IO) -> Grammar:
    tree = ET.parse(file)
    root = tree.getroot()
    rules = []
    for rule in root.find('./grammar/rules'):
        rules.append(parse_rule(rule))
    states = []
    for state in root.find('./automaton'):
        states.append(parse_state(state, rules))
    return Grammar(rules, states)


skeleton = """\
#ifndef GRAMMAR_H
#define GRAMMAR_H

#include <map>
#include <string>
#include <utility>
#include <vector>

struct Rule {
    std::string              lhs;
    std::vector<std::string> rhs;
};

struct StateRule {
    int                      rule;
    int                      point;
    int                      transition;
    std::vector<std::string> lookaheads;
};

struct State {
    int                    number;
    std::vector<StateRule> rules;
};

"""

if __name__ == "__main__":
    if len(sys.argv) != 3:
        sys.exit(f'Usage: {sys.argv[0]} <input> <output>')
    with open(sys.argv[1]) as grammarXML:
        grammar = process_grammar(grammarXML)
    with open(sys.argv[2], 'w') as output:
        output.writelines(skeleton)

        output.write('const Rule rules[] = {\n')
        sep = ''
        for rule in grammar.rules:
            output.write(fr'{sep}    {{{rule.lhs}, {{')
            sep = ',\n'
            sep2 = ''
            for s in rule.rhs:
                output.write(f'{sep2}{s}')
                sep2 = ','
            output.write('}}')
        output.write('\n};\n\n')

        output.write('const State states[] = {\n')
        sep = ''
        for state in grammar.states:
            output.write(f'{sep}    {{')
            sep = ',\n'
            sep2 = ''
            output.write(f'{state.number},{{')
            for stateRule in state.rules:
                output.write(f'{sep2}{{{stateRule.rule},{stateRule.point},{stateRule.transition},{{')
                sep3 = ''
                for lah in stateRule.lookaheads:
                    output.write(f'{sep3}{lah}')
                    sep3 = ','
                sep2 = ','
                output.write('}}')
            output.write('}}')
        output.write('\n};\n\n')

        output.write('#endif // GRAMMAR_H\n')
